# 1. Цели и предпосылки

## 1.1 Зачем идём в разработку продукта?
- **Рост нагрузки и скорость обработки.** Ежедневно в соцсети появляется до 500 000 комментариев — модерировать их вручную невозможно: это дорого и медленно.  
- **Объективность и консистентность.** Человеческий фактор приводит к разным решениям по похожим комментариям (субъективизм модераторов).  
- **Снижение рисков штрафов.** Роскомнадзор предъявляет строгие требования к своевременной блокировке нежелательного контента. Автоматизация поможет не пропустить критичные случаи.  
- **Увеличение вовлечённости.** Анализ тональности в режиме реального времени позволяет быстрее реагировать на негатив, предлагать пользователям релевантный позитивный контент и улучшать качество ленты.

## 1.2 Почему станет лучше от использования ML?
- **Скорость.** Модель классифицирует сотни тысяч комментариев за секунды, вместо нескольких десятков модераторов.  
- **Масштабируемость.** С ростом аудитории нагрузка растёт линейно, но ML-система масштабируется горизонтально в облаке.  
- **Консистентность решений.** Алгоритм даёт единообразную оценку тональности, настраиваемую в зависимости от бизнес-правил.  
- **Адаптивность.** Модель может дообучаться на новых примерах «токсичных» или «разрешённых» комментариев и учитывать изменяющийся язык пользователей.

## 1.3 Бизнес-требования и ограничения
- **SLA модерации:** все комментарии с негативом/нарушениями должны быть отмечены в течение **1 часа** после публикации.  
- **Доступность системы:** ≥ 99.5 % в мес. (не более 3.6 ч простоев).  
- **GDPR и локальные законы:** хранение и обработка персональных данных пользователей в соответствии с требованиями (IP-адрес, никнейм).  
- **Бюджет:** первичная разработка — до 20 000 USD, эксплуатация — до 2 000 USD/мес.  
- **Команда:** 2–3 инженера, 1 ML-разработчик, 1 аналитик.

## 1.4 Функциональные и нефункциональные требования

| Тип                     | Требование                                                                                                                                                  |
|-------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------|
| **Функциональные**      | 1. Классификация комментариев по тональности (позитив, нейтрал, негатив).<br>2. Выделение токсичных/скрывающих спам сообщений.<br>3. Публикация отчётов. |
| **Нефункциональные**    | 1. Latency: ≤ 200 мс на обработку одного комментария.<br>2. Throughput: ≥ 5 000 комментариев/сек.<br>3. Безопасность API (OAuth2, HTTPS).                 |

## 1.5 Процесс пилота и критерии успеха
1. **Сбор данных:** исторические комментарии (30 000) с ручными метками модераторов.  
2. **Разделение:** train (70 %), validation (15 %), test (15 %).  
3. **Обучение базовой модели:** классификатор на трансформерах (например, RuBERT).  
4. **Валидация:** по метрикам F1, precision/recall, latency.  
5. **A/B-тест в продакшене:** 10 % трафика модерации переводится через ML-систему.  
6. **Критерии успеха:**  
   - **F1-score ≥ 0.85** на тестовой выборке;  
   - **Latency в продакшене ≤ 200 мс** для 95 % запросов;  
   - **Снижение ручной модерации на 50 %** (по количеству обращений модераторов).

## 1.6 MVP vs технический долг
- **В MVP включить:**  
  1. Базовую классификацию тональности (3 класса).  
  2. REST-API для синхронного вызова.  
  3. Минимальный дашборд (отчёты по количеству негативных/позитивных).  
- **Оставить в техдолге:**  
  1. Дообучение онлайн (стриминг новых меток).  
  2. Распознавание сарказма через мультимодальность.  
  3. Автоматическая коррекция классификации на основе фидбека модераторов.

# 2. Методология

## 2.1 Технический подход
- **Тип модели:** классификация текста (multi-class classification).  
- **Алгоритм:** трансформеры (fine-tuning RuBERT или похожей модели).  
- **Инструменты:** Python, PyTorch, Hugging Face Transformers, Docker.

## 2.2 Необходимые данные
- **Комментарии:** текст, метки тональности (позитив/нейтрал/негатив).  
- **Метаданные:** user_id, content_id, timestamp.  
- **История модерации:** ручные решения модераторов.  
- **Опционально:** дополнительные сигналы (число лайков, жалоб, длина комментария).

## 2.3 Метрики качества и связь с бизнес-результатом
| Метрика         | Описание                                           | Связь с бизнесом                              |
|-----------------|----------------------------------------------------|-----------------------------------------------|
| **Precision**   | Доля корректно найденных негативных комментариев.  | Снижает количество ложноположительных блокировок (ユーザー‐experience). |
| **Recall**      | Доля обнаруженных всех негативных.                 | Минимизирует риск штрафов от РКН.             |
| **F1-score**    | Гармоническое среднее precision и recall.          | Баланс между безопасностью и UX.              |
| **Latency (p95)** | Время обработки 95 % запросов.                   | Соответствие SLA ≤ 200 мс.                    |

## 2.4 Риски и планы по смягчению
- **Дисбаланс классов:** негативных комментариев меньше. → использовать oversampling, loss-weighting.  
- **Шумные метки:** возможны ошибки в ручных разметках. → провести ревью разметки, отбраковать спорные примеры.  
- **Изменение языка:** сленг, новые мемы. → регулярное дообучение модели, мониторинг «дрифта» данных.  
- **Перегрузка инфраструктуры:** пиковые нагрузки. → авто-скейлинг Kubernetes, rate limiting.

# 3. Подготовка пилота

## 3.1 Способ оценки
- Выдача прогнозов на отложенной тестовой выборке (15 %).  
- A/B-тест: сравнение ручной и автоматической модерации по KPI (F1, latency, % false positive).

## 3.2 Что считаем успешным пилотом
- **F1 ≥ 0.85** на тестовой выборке.  
- **Latency p95 ≤ 200 мс** под нагрузкой 1 000 запросов/сек.  
- **Сокращение ручной работы** модераторов минимум на 40 %.

## 3.3 Шаги подготовки
1. Интеграция API ML-модуля в тестовую среду.  
2. Наполнение «песочницы» историческими данными.  
3. Настройка метрик мониторинга (Prometheus + Grafana).  
4. Проведение dry-run (обработка старых комментариев, не влияя на прод).

# 4. Внедрение в production

## 4.1 Архитектура решения
```text
[Load Balancer]
       ↓
[Kubernetes Ingress] ──▶ [API Service (FastAPI + Docker)] ──▶ [ML Model Pods (RuBERT)]
       ↓                                               ↘
[Metrics Exporter]                                      └─▶ [Logging & Audit Service]
       ↓
[Prometheus] → [Grafana]
```

### 4.1 Компоненты решения

- **API Service**  
  Принимает HTTP-запросы с текстом комментария, вызывает ML-модуль и возвращает прогноз тональности.

- **ML Model Pods**  
  Kubernetes-подами развернуты несколько экземпляров модели (sharding по трафику) для горизонтального масштабирования и высокой доступности.

- **Logging & Audit**  
  Сохраняет в БД или лог-хранилище: входные данные, предсказание модели и окончательное решение модератора.

- **Monitoring**  
  Сбор метрик:  
  - **Latency** (время ответа API)  
  - **Error rate** (процент неуспешных запросов)  
  - **Throughput** (RPS)  

---

### 4.2 Инфраструктура и масштабируемость

- **Kubernetes on Cloud** (например, GKE, AKS, EKS)  
  - **Плюсы:**  
    - Авто-скейлинг под нагрузкой  
    - Self-healing и отказоустойчивость  
    - Простая интеграция с CI/CD (GitHub Actions, GitLab CI)  
  - **Минусы:**  
    - Стоимость выше self-managed кластера  
    - Более сложная первоначальная настройка и отладка  

- **Хранение данных**  
  - **Hot storage:** NoSQL (Cassandra) для быстрых OLTP-запросов и низкой латентности.  
  - **Cold storage:** Объектный стор (S3-совместимый) для исторических данных, аудита и переобучения моделей.  

---

### 4.3 Требования к работе системы

- **SLA:** доступность ≥ 99.5 % (не более 3.6 ч простоев в месяц)  
- **RPS:** пиковая нагрузка до 10 000 запросов/сек  
- **Latency:**  
  - p50 ≤ 100 мс  
  - p95 ≤ 200 мс  
- **Безопасность:**  
  - HTTPS/TLS для всего трафика  
  - Аутентификация и авторизация через OAuth2  
  - Шифрование данных in transit и, при необходимости, at rest  

---

### 4.4 Риски и неопределённости

- **Дрифт данных:**  
  Языковые изменения (новый сленг, мемы) → регулярный мониторинг качества модели и дообучение.  

- **Непредвиденные пиковые нагрузки:**  
  Резкое увеличение трафика → подготовить «горячие» резервы под ML-поды и включить rate-limiting.

- **Зависимость от внешних сервисов:**  
  Сбой Cassandra или Object Store → возможно падение доступности сервиса.  
  _Митигирующий план:_ кеширование последних предсказаний, fallback на упрощённую логику.

- **Регуляторные изменения:**  
  Новые требования РКН или GDPR → обеспечить возможность быстрой правки и деплоя правил классификации без полного ребилда модели.
